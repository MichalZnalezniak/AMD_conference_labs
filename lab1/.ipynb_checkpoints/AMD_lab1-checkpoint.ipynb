{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPY1-2Q5tCtF"
   },
   "source": [
    "# Deep Learning with AMD devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for today\n",
    "\n",
    "1. Learn about ROCm\n",
    "    - Understand what is ROCm.  \n",
    "    - Get familiar with AMD GPUs that have ROCm support.  \n",
    "    - PyTorch interface for AMD GPUs.  \n",
    "2. See it's usages in pratice\n",
    "    - Classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROCm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Radeon Open Compute Ecosystem (ROCm)** is the general-purpose computing platform. Unlike CUDA, the ROCm software stack can take advantage of several domains, such as general-purpose GPGPU, high-performance computing (HPC), and heterogeneous computing.\n",
    "\n",
    "Since **PyTorch 1.8** release, users of PyTorch can use the ROCm™ open software platform to speed up compute-intensive applications by harnessing the power of GPUs. This provides a option for data scientists, researchers, students, and others in the community to get started with accelerated PyTorch using AMD GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMD GPUs with ROCm support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROCm officially supports AMD GPUs that use following chips:\n",
    "\n",
    "- **Vega**\n",
    "\n",
    "  - Vega 10 chips, such as [Radeon Instinct MI25](https://www.amd.com/en/products/professional-graphics/instinct-mi25)\n",
    "\n",
    "  - Vega 20 chips, such as on the [Radeon Instinct MI50](https://www.amd.com/en/products/professional-graphics/instinct-mi50), [Radeon Instinct MI60](https://www.amd.com/system/files/documents/radeon-instinct-mi60-datasheet.pdf) or [AMD Radeon VII](https://www.amd.com/en/support/graphics/amd-radeon-2nd-generation-vega/amd-radeon-2nd-generation-vega/amd-radeon-vii), [Radeon Pro VII](https://www.amd.com/en/support/professional-graphics/radeon-pro/radeon-pro-vii/radeon-pro-vii)\n",
    "   \n",
    "\n",
    "- **CDNA GPUs**\n",
    "\n",
    "   - MI100 chips such as on the [AMD Instinct™ MI100](https://www.amd.com/en/graphics/instinct-server-accelerators)\n",
    "   \n",
    "   - MI200 chips such as on the [AMD Instinct™ MI200](https://www.amd.com/en/graphics/instinct-server-accelerators)\n",
    "   \n",
    "- **RDNA GPUs**\n",
    "\n",
    "   - [RDNA2](https://www.amd.com/en/technologies/rdna)\n",
    "   \n",
    "   - [RDNA3](https://www.amd.com/en/technologies/rdna)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROCm and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIP is ROCm’s C++ dialect designed to ease conversion of CUDA applications to portable C++ code.\n",
    "\n",
    "PyTorch for HIP intentionally reuses the existing torch.cuda interfaces. This helps to accelerate the porting of existing PyTorch code and models because very few code changes are necessary, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install thop\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # show the number of GPUs available.\n",
    "    print(torch.cuda.device_count())\n",
    "    # do something specific for HIP - check HIP version\n",
    "    print(torch.version.hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_default = torch.device('cuda')     # Default HIP device -> cuda:0\n",
    "cuda_zero = torch.device('cuda:0')     # Default HIP device\n",
    "cuda_one = torch.device('cuda:1')\n",
    "\n",
    "x = torch.tensor([1., 2.], device=cuda_default)\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "# y.device is default cuda device\n",
    "z = torch.tensor([1., 2.], device=cuda_zero)\n",
    "# z.device is device(type='cuda', index=0)\n",
    "z = x + y\n",
    "# z.device is device(type='cuda', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    x = torch.tensor([1., 2.], device=cuda_default)\n",
    "    y = x.cpu()\n",
    "    z = x + y\n",
    "\n",
    "except RuntimeError as e:\n",
    "        print(f'RuntimeError: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    x = torch.tensor([1., 2.], device=cuda_one)\n",
    "\n",
    "except RuntimeError as e:\n",
    "        print(f'RuntimeError: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with ROCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEOcjR0stCtK"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from thop import profile, clever_format\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's lab we will use **CIFAR10** dataset. Here are some images from the datase:\n",
    "![cifar10](https://miro.medium.com/max/709/1*LyV7_xga4jUHdx4_jHk1PQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "grayscale_transform = transforms.RandomGrayscale(p=1)\n",
    "horizontal_flip_transform = transforms.RandomHorizontalFlip(p=1)\n",
    "color_jiter_transform = transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=1)\n",
    "\n",
    "images_transformed = []\n",
    "for u in range(8):\n",
    "    example_input = validation_dataset[u][0]\n",
    "    images_transformed.append(torch.stack((example_input, grayscale_transform(example_input), \n",
    "                             horizontal_flip_transform(example_input), color_jiter_transform(example_input))))\n",
    "images_transformed = torch.stack(images_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(images_transformed.reshape(32, 3, 32, 32), nrow=4)\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def get_dataloaders():\n",
    "    transform_train = transforms.Compose([\n",
    "                                    transforms.Resize((32,32)),                                \n",
    "                                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "                                    transforms.RandomGrayscale(p=0.2),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "                                     ])\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "                                   ])\n",
    "\n",
    "    training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) # Data augmentation is only done on training images\n",
    "    validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=len(validation_dataset), shuffle=False, pin_memory=True, num_workers=8)\n",
    "    \n",
    "    return training_loader, validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Residual Blocks \n",
    "\n",
    "One of the key factors of our CNN model is the addition of the residual block, which adds the original input back to the output feature map obtained by passing the input through one or more convolutional layers.\n",
    "\n",
    "![](https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)\n",
    "\n",
    "Residual Block overcame the “vanishing gradient” problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_CIFAR10(nn.Module):\n",
    "    def __init__(self, type=''):\n",
    "        super(ResNet18_CIFAR10, self).__init__()\n",
    "        self.f = []\n",
    "        for name, module in resnet18(pretrained=True).named_children():\n",
    "            if not isinstance(module, nn.Linear):\n",
    "                self.f.append(module)\n",
    "        # encoder\n",
    "        self.feature_extractor = nn.Sequential(*self.f)\n",
    "        self.linear = nn.Linear(512, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        feature = torch.flatten(x, start_dim=1)\n",
    "        out = self.linear(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_K3_CIFAR10(nn.Module):\n",
    "    def __init__(self, type=''):\n",
    "        super(ResNet18_K3_CIFAR10, self).__init__()\n",
    "        self.f = []\n",
    "        for name, module in resnet18(pretrained=True).named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if not isinstance(module, nn.Linear):\n",
    "                self.f.append(module)\n",
    "        # encoder\n",
    "        self.fe = nn.Sequential(*self.f)\n",
    "        self.linear = nn.Linear(512, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fe(x)\n",
    "        feature = torch.flatten(x, start_dim=1)\n",
    "        out = self.linear(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_K3_NoMaxPool_CIFAR10(nn.Module):\n",
    "    def __init__(self, type=''):\n",
    "        super(ResNet18_K3_NoMaxPool_CIFAR10, self).__init__()\n",
    "        self.f = []\n",
    "        for name, module in resnet18(pretrained=True).named_children():\n",
    "            if name == 'conv1':\n",
    "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
    "                self.f.append(module)\n",
    "        # encoder\n",
    "        self.fe = nn.Sequential(*self.f)\n",
    "        self.linear = nn.Linear(512, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fe(x)\n",
    "        feature = torch.flatten(x, start_dim=1)\n",
    "        out = self.linear(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, train_optimizer, epoch, epochs):\n",
    "    model.train()\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)      \n",
    "    for data in train_bar:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move to the GPU\n",
    "        inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_num += batch_size\n",
    "        total_loss += loss.item() * batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
    "    return total_loss / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, data_loader, epoch, epochs):\n",
    "    model.eval()\n",
    "    accuracy, total_num, valid_bar = 0, 0, tqdm(data_loader)\n",
    "    labels_array, prediction_array = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in valid_bar:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Move to the GPU\n",
    "            inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            accuracy = accuracy_score(labels.cpu(), predicted.cpu())\n",
    "\n",
    "            valid_bar.set_description('Valid Epoch: [{}/{}] Accuracy: {:.4f}'.format(epoch, epochs, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(model, optimizer):\n",
    "    training_loader, validation_loader = get_dataloaders()\n",
    "    epochs = 10\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        loss_list.append(train(model, training_loader, optimizer, epoch, epochs))\n",
    "        accuracy_list.append(valid(model, validation_loader, epoch, epochs))\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    \n",
    "    axes[0].plot(loss_list, label='Loss value')\n",
    "    axes[0].set_title('Loss value')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss value')\n",
    "    axes[1].plot(accuracy_list, label='Accuracy')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    \n",
    "    fig.legend()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_CIFAR10().cuda()\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "start_train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_K3_CIFAR10().cuda()\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "start_train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_K3_NoMaxPool_CIFAR10().cuda()\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "start_train(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this lab, we have learned how to train a deep neural network with PyTorch framework on the AMD GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
